\chapter{Related Work} \label{chap_related_work}

This section will give an overview of the current state of research on Convolutional Neural Networks. 

\section{Convolutional Neural Networks}
The mathematical fundamentals for Convolutional Neural Networks was introduced as early as in the 1980s by Kunihiko Fukushima\cite{Fukushima1980}\cite{Fukushima1982}, in form of the \textit{neocognitron} model. The model was later improved in 1998 by  Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner - who introduced the \textit{Convolutional Neural Network} model. In 2003 the model was simplified by Patrice Simard, David Steinkraus, and John C. Platt \cite{Simard2000}, in an attempt to make it easier to implement. The paper also mentions two of the main issues with CNNs: the size of the training set and the time spent training. In order to achieve high enough accuracy a CNN requires thousands of training samples, which needs to be labeled. Processing all of these samples and fine-tuning the networks takes a great amount of processing power, causing training to take days or weeks. These issues are the ones that caused CNNs not to gain popularity before mid-2000. The rise of the Internet, digital cameras, and Big Data have provided us with vast amounts of images which can be used for training. Improvements in the speed and sophistication of computer hardware have reduced the training time from days/weeks to hours. E.g. \cite{Cires2003} purposes a GPU implementations which reduced the epoch (see Section \ref{sec_ann_training}) training time from 35 hours to 35 minutes. This demonstrates that highly parallel hardware vastly increases the effiency of neural networks compared to CPUs. 

These recent advancements have renewed the interest in neural networks, and increased the research done on the field. As a result CNNs have become a leading model within pattern recognition for computer vision. This can be illustrated by the fact that CNNs implementations have won several pattern recognition contests in the period 2009-2012, including IJCNN 2011 Traffic Sign Recognition Competition\cite{Ciresan2012} and the ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge\cite{DanC.Ciresan2012}.


\section{Convolutional Neural Network in Hardware} \label{sec_related_work_cnn}

There have been several proposed hardware architectures during the last decade, including \textbf{ADD LIST}. Below we will describe some of the more recent and relevant architectures. 

In \cite{Farabet2009} a CNN was implemented on a Virtex-4 SX35 FPGA from Xilinx. In this implementation all the fundamental computations were hard-wired, and controlled by a 32~bit soft processor using macro instructions. Training was done offline, and a representation of the network was provided to the soft processor. With this implementation they were able to process a $ 512 \times 384 $ grayscale image in 100\textit{ms}, i.e. 10 frames per second. The design was intented for use in low power embedded vision  systems, e.g. robots, and the whole curcuit board used less than 15 W.

Farabet and LeCun later improved the mentioned architecture in \cite{Farabet2010}. In this design they added multiple parallel vector processing units and allowed individual
streams of data to operate seamlessly within processing blocks. They were able to achieve 30 frames per second using 15 W. In addition they predicted a planned ASIC implementation of the system would increase the processing speed and reduce the power to 1 W. 


In \cite{Chakradhar2010} they explore how they can exploit the different the parallel nature of CNNs. They introduce types of parallelism found in CNNs, \textit{inter-output} and \textit{intra-output}. The first one comes from the observation that each feature map and the corresponding subsampling/pooling computation can be done in parallel. This is easily seen in the first layer. The second one refers to that the convolution of several inputs are combined to produce one feature map (see Figure \ref{fig_visual_conv_ss_mp}), where the individual convolutions can be done in parallel. This one is present in all of the convolution layers after the first layer. They exploit these observations by purposing a dynamically configurable coprocessor on a FPGA, which can switch between computing several different feature maps in parallel and processing several inputs to compute one feature map. By doing this they are able to fully utilize the parallel nature of a CNN and reduce the intermediate storage on the FPGA. Using a Virtex 5 SX240T FPGA with 1024 multiply-accumulate units they were able to outperform  a 2.3 GHz quad-core, dual socket Intel Xeon, and a 1.35 GHz C870 GPU by 4x to 8x. 

\cite{Paper} presents an architecture they named the \textit{nn-X}. For the implementation they used a Xilinx ZC706 platform, containing a Kintex-7 FPGA and two ARM Cortex-A9. They made acceleration units for the convolution and subsampling/pooling layers on the FPGA, while the fully-connected layers was processed by the ARM processors. This implementation seems to be the fastest of all the purposed FPGA implementations to date, able to perform up to 227 G-ops/s. In addition it seems to be the most energy efficient across all platforms, by being able to perform 25 G-ops/s-Watt. In the paper they compared it to a Intel i7-3720QM and a NVIDIA’s GTX 780 GPU, where it was shown that it was up to 20x more power efficient. This makes a strong case for hardware acceleration of CNNs in applications designed for energy efficiency. 


