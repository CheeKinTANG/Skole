\chapter{Future work}

As mentioned, due to lack of time the Imagezor architecture was not deployed on a FPGA and tested on it. This should be done in order to give a more accurate comparison to CPU/GPUs implementations.

In addition the fully connected layer has not been implemented. There are two ways to do this, either in software or hardware. A software implementation can actually be worthwhile, since the convolution and subsample/pooling layers can be very resource demanding.  I.e. both the fully connected layer and the convolution layers require DSP slices for a cost effective acceleration, which leads to a fight over resources. Giving more slices to one might reduce the performance of the other. So unless one have a great amount of DSP slices available, doing the fully connected layer in software might be the best choice. This was done in \cite{Paper}, with great success.

Hardware accelerating the training of the network was not explored in this report. This is a interesting topic that should be investegated, especially with warhouse computing in mind. With the vast amount of data available with Big Data, warhouse clusters have a vast potential for learning patterns in this data, be it for object recognition in images or other patterns. Since the primary cost of warhouse computing is the power bill, clusters focusing on neural networks would greatly benefit from a power efficient hardware accelerator for training. 

Since the main motivation for this project was to explore the possibility of making a SHMAC tile to accelerate a machine learning algorithm, further projects should extend the current architecture in order to achieve this.